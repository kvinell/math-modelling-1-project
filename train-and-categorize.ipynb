{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import libraries to use\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn import model_selection, preprocessing\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define sigmoid function\n",
    "def sigmoid(z):\n",
    "    # TODO\n",
    "    # Hint: use np.exp function provided by Numpy library\n",
    "    # return ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the prediction function\n",
    "def predict(features, weights):\n",
    "    # TODO: how large should the threshold be to amply categorize the feature vector?\n",
    "    # threshold=???\n",
    "    return sigmoid(np.dot(features, weights)) >= threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define cost function\n",
    "def cost(y_hat, y):\n",
    "    # TODO\n",
    "    # Hint: use np.log function provided by Numpy library and mean function\n",
    "    # return ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the gradient function\n",
    "def gradient(features, predictions, true_labels):\n",
    "    # TODO\n",
    "    # Hint: use transpose function (e g x.T) and np.dot from Numpy library\n",
    "    # return ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add intercept\n",
    "def add_intercept(features):\n",
    "    intercept = np.ones((features.shape[0], 1))\n",
    "    return np.concatenate((intercept, features), axis=1)\n",
    "\n",
    "def fit(features, true_labels, learning_rate, iterations):\n",
    "    # Add intercept\n",
    "    features = add_intercept(features)\n",
    "    # Initialize weights\n",
    "    weights = np.zeros(features.shape[1])\n",
    "        \n",
    "    # Run iterations with gradient descent\n",
    "    for current_iteration in range(iterations):\n",
    "        # TODO\n",
    "        # Hint: use np.dot function from Numpy\n",
    "        #z = ???\n",
    "        predictions = sigmoid(z)\n",
    "        grad = gradient(features, predictions, true_labels)\n",
    "        weights = weights - learning_rate * grad\n",
    "\n",
    "        # Performance printout\n",
    "        if (current_iteration % 1000 == 0):\n",
    "            current_cost = cost(predictions, true_labels)\n",
    "            print(\"Cost: {c}\".format(c=current_cost))\n",
    "    \n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_accuracy(predictions, labels):\n",
    "    return (predictions == labels).sum()/labels.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "url = \"https://raw.githubusercontent.com/kvinell/math-modelling-1-data/master/creditcard_fraud.csv\"\n",
    "dataset = pd.read_csv(url, sep = \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract features (first 30 columns are features)\n",
    "all_features = dataset.iloc[:, 0:30]\n",
    "# Extract category labels (last column) and turn into binary variable\n",
    "labels = dataset.loc[:, 'Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Feature engineering\n",
    "\n",
    "# Hint: you can either drop columns that we do not want to use as features in the model...\n",
    "selected_features = all_features.drop([\"V5\", \"V6\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ...or actively select columns that we want to use in the model\n",
    "selected_features = all_features.loc[:, [\"Amount\", \"V1\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Divide dataset into training and test\n",
    "seed = 1\n",
    "test_size = 0.20 # 20% of the dataset as test data is customary for many cases\n",
    "features_train, features_test, labels_train, labels_test = sklearn.model_selection.train_test_split(selected_features, labels, test_size=test_size, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute optimal weights\n",
    "\n",
    "# TODO: experiment with different values of learning rate and number of iterations\n",
    "# Do you get different results?\n",
    "learning_rate = 0.01\n",
    "number_of_iterations = 2000\n",
    "optimal_weights = fit(features_train, labels_train, learning_rate, number_of_iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute predictions\n",
    "# WARNING: you need to re-generate the features of the test set (features_test) to re-run this cell!\n",
    "features_test = add_intercept(features_test)\n",
    "predictions = predict(features_test, optimal_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute accuracy of model\n",
    "accuracy = compute_accuracy(predictions, labels_test)\n",
    "print(\"Accuracy of model: {accuracy} %\".format(accuracy=100*accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
